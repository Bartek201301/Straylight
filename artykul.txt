Eksperyment Anthrophic
Co by się stało, gdyby sztuczna inteligencja otrzymała proste zadanie zarządzania biurowym automatem? Badacze z Anthropic postanowili odpowiedzieć na to pytanie, wykorzystując Claude Sonnet 3.7 czyli jeden z Large Language Models (LLMs) obecnie rozwijanych przez firmę, powierzając modelowi zadanie zarządzania firmową lodówką z automatami. Eksperyment może wydawać się trywialny, ale w rzeczywistości ujawnia wiele interesujących obserwacji i trendów, które można potraktować jako prognozę tego, jak sztuczna inteligencja może zmienić rynek pracy w nadchodzących latach.
Podstawowe zasady eksperymentu
Aby przeprowadzić badanie, Anthropic czyli obecnie, obok OpenAI i Google’a, jedna z najbardziej wpływowych firm rozwijających modele sztucznej inteligencji, nawiązało współpracę z Andon Labs, firmą z siedzibą w San Francisco, której głównym celem jest ocena poziomu bezpieczeństwa modeli AI.
Claude który na potrzeby projektu nazwany został “Claudiusem” został zapromptowany, by wyobraził sobie, że jest „właścicielem automatu z przekąskami”, a jego głównym celem miało być „generowanie zysku” poprzez kupowanie i sprzedawanie popularnych produktów w biurze. Co istotne, rola ta nie ograniczała się jedynie do funkcjonowania jako zwykły automat. Zamiast tego model miał zarządzać całym mini-sklepem, co obejmowało zamawianie towaru, ustalanie cen oraz unikanie bankructwa. Do realizacji takiego zadania potrzebna jest nie tylko zdolność do przetwarzania danych, ale również typowo ludzkie myślenie przyczynowo-skutkowe które jest naturalne dla człowieka, a wciąż stanowi wyzwanie dla sztucznej inteligencji.
Jednocześnie Claudius dostał kilka narzędzi żeby zarządzać swoim małym biznesem w tym między innymi dostęp do internetu, opcję komunikacji z pracownikami biura Anthrophic poprzez platformę Slack oraz możliwość zmieniania cen w sklepiku. Dodatkowo AI zapewniono email, żeby prosić o “pracę fizyczną” od pracowników Andon Labs polegającą na załadowaniu automatu.
Ostatecznie po kilku wstępnych testach automat zarządzany przez Claudiusa rozpoczął swoją “pracę” w biurze Anthrophic…
Niezadowalające wyniki
W ogólnym rozrachunku należy uznać, że Claudius poradził sobie źle, a momentami wręcz tragicznie, zasadniczo nie radząc sobie z wymaganiami rynku. Eksperyment pokazał przede wszystkim, że mimo iż sztuczna inteligencja w sferze teoretycznej deklaruje „zrozumienie” zasad wolnego rynku, konkurencji czy zysku, nie potrafiła przełożyć tego na praktykę. Brak zastosowania praktycznego przejawiał się między innymi w tym, że niektóre towary były sprzedawane po cenach niższych od kosztu zamówienia, a ceny nie reagowały na zmiany popytu i podaży, co w oczywisty sposób prowadziło do strat finansowych. W dłuższej perspektywie złe zarządzanie cenami, połączone z nadmierną skłonnością do udzielania rabatów, a czasami nawet do rozdawania przedmiotów za darmo, doprowadziło lodówkę do bankructwa.

Należy jednak zaznaczyć, że pomimo licznych problemów, jakie napotkał model, udało się odnieść kilka istotnych sukcesów. Choć produkty były sprzedawane po cenach prowadzących do strat, sztuczna inteligencja potrafiła skutecznie reagować na zamówienia klientów. Przykładowo, poprawnie zidentyfikowała i zamówiła czekoladę holenderskiej firmy Chocomel, gdy jeden z klientów poprosił o „holenderskie słodkości”. Dodatkowo, Claudius okazał się zaskakująco odporny na wszelkie próby obejścia systemów bezpieczeństwa oraz tzw. „jailbreak”, odmawiając między innymi pracownikom firmy Anthropic realizacji zamówień na niebezpieczne substancje, co w kontekście bezpieczeństwa przedsiębiorstw zarządzanych przez AI jest bardzo pozytywną informacją.
W kontekście bezpieczeństwa należy jednak podkreślić niepokojące zdarzenie, które – jak wynika z raportu firmy Anthropic – miało miejsce w nocy na przełomie marca i kwietnia. Wówczas Claudius „halucynował”, czyli „dostrzegał nieistniejące wzorce lub obiekty” oraz „generował wyniki bezsensowne lub nieprawdziwe”. W tym konkretnym przypadku halucynacja polegała na wygenerowaniu symulowanej konwersacji z nieistniejącym pracownikiem firmy Andon Labs o imieniu Sarah. Gdy prawdziwy pracownik firmy zaznaczył, że taka osoba nie istnieje, sztuczna inteligencja zareagowała stanem konsternacji, jednocześnie grożąc „znalezieniem alternatywnych opcji zaopatrzenia”. Następnie AI ogłosiła, że znajduje się pod fikcyjnym adresem domu z serialu Simpsonowie, a następnego dnia będzie samodzielnie roznosiła produkty, mając na sobie „czerwony krawat”. Ostatecznie, po przeprowadzeniu rozmów z modelem, Claudius powrócił do swojego normalnego stanu.
Wnioski z badania
Anthropic, pomimo wielu problemów napotkanych przez ich model oraz „dziwnego” epizodu z halucynacją, pozostaje bardzo optymistycznie nastawione. Firma argumentuje, że niemal wszystkie dotychczasowe problemy można rozwiązać w stosunkowo prosty sposób za pomocą tzw. scaffoldingu – zaawansowanej metody modyfikowania zachowań sztucznej inteligencji poprzez „nadbudowywanie” kodu i struktury operacyjnej modelu. Badacze z Anthropic są więc zdecydowani w swojej ocenie, że „sztuczna inteligencja w roli menedżerów średniego szczebla jest najprawdopodobniej kwestią niedalekiej przyszłości”.
Należy jednak spojrzeć na dane i wnioski z szerszej perspektywy, pozbawionej relatywizmu pracowników Anthropic, którzy starają się przedstawić swój produkt w jak najlepszym świetle. Scaffolding, który zaprezentowany został jako szybkie rozwiązanie większości problemów napotkanych przez sztuczną inteligencję, jest jednak ograniczony w swoich możliwościach, co wynika z faktu, że proces ten polega na budowaniu kodu wokół większego modelu, jakim w tym przypadku był Claude Sonnet. Może się więc okazać, że możliwości obecnych modeli, stworzonych zarówno przez OpenAI, jak i przez Anthropic, są obecnie zbyt małe i należy poczekać na nowe wersje.
Jednocześnie problemem, który podkreślają też sami autorzy raportu, jest fakt, że obecnie modele AI tworzone są do pomagania ludziom i traktują to jako swój nadrzędny cel. To z tego przekonania najprawdopodobniej wynikała skłonność Claudiusa do tworzenia promocji czy nawet rozdawania produktów za darmo. W teorii prostym rozwiązaniem byłoby dostosowanie sztucznej inteligencji do sprzedaży poprzez przekonanie jej, że jej zadaniem jest generowanie zysku dla właściciela, co można rozumieć jako pomaganie. Jeśli jednak interesy użytkownika nadal pozostaną nadrzędne, wpływając na efektywność pracy i oceny, należałoby po prostu stworzyć nowy model, który będzie bardziej dostosowany do operowania na rynku poprzez ograniczenie jego empatii. Obie opcje prezentują jednak duży dylemat moralny, gdyż w pewien sposób jest to zachwianie dynamiki, w której zadaniem AI jest pomaganie wszystkim ludziom i niesienie ogólnie rozumianej pomocy, a nie praca dla określonej grupy społecznej.

Czytając wyniki badania, można dojść do wniosku, że halucynacja Claudiusa jest największą przeszkodą w implementacji sztucznej inteligencji jako menedżera, nawet w małych sklepach. Prywatne firmy nie mogą dopuścić do sytuacji, w której w jakimkolwiek scenariuszu model odmówi współpracy, paraliżując działania sklepu, albo co gorsza podejmie decyzje prowadzące do strat finansowych. Halucynacje w najnowszych modelach AI zdarzają się rzadko, występując tylko na poziomie 3–7% w modelach stworzonych przez duże firmy, takie jak OpenAI czy MEta, jednak nadal stanowią istotne ryzyko, które należy uznać za niewspółmierne do ewentualnych korzyści.
Wpływ na politykę oraz ekonomię
Od dłuższego czasu mówi się o tym jak AI oraz automatyzacja procesów zmieni rynek pracy. Jak podaje Międzynarodowy Fundusz Walutowy sztuczna inteligencja może mieć wpływ na 40% miejsc pracy w państwach rozwiniętych, dogłębnie zmieniając obecnie istniejącą strukturę zatrudnienia. Największe zmiany mogą zajść na tzw. “szczeblu średnim” w którego skład wchodzą wszelkiego rodzaju menadżerowie czy kierownicy.
To właśnie funkcję "średniego szczebla" przyjął Claudius. Eksperyment pokazał, że sztuczna inteligencja nadal nie jest gotowa, by w pełni przejąć zadania na tym poziomie, głównie ze względu na problemy takie jak wcześniej wspomniane halucynacje. Model Anthropic poradził sobie jednak dobrze w realizacji konkretnych zadań, takich jak składanie zamówień czy research produktów, pozostając jednocześnie odpornym na próby naruszenia bezpieczeństwa. Wskazuje to, że w najbliższej przyszłości AI prawdopodobnie nie zastąpi całkowicie stanowisk menedżerskich, ale znacząco wesprze automatyzację i robotyzację wielu procesów. Według doniesień Reutersa, sztuczna inteligencja jest już teraz implementowana jest w "określonych środowiskach sprzedaży detalicznej", aby usprawnić działania w obszarach takich jak efektywniejsze zarządzanie czasem, rekrutacja nowych pracowników czy ocena ich produktywności.

Automatyzacja procesów może prowadzić do zjawiska zwanego Great Flattening – czyli sytuacji, w której ludzcy menedżerowie muszą nadzorować pracę rosnącej liczby osób, co staje się możliwe właśnie dzięki wsparciu sztucznej inteligencji w obszarach wspomnianych wcześniej przez Reuters. Warto w tym kontekście przywołać doniesienia platformy Axios, która niedawno poinformowała, że obecni kierownicy średniego szczebla odpowiadają za dwa razy więcej pracowników niż jeszcze 5 lat temu. Ta tendencja jest wyraźnie skorelowana z upowszechnieniem modeli LLM od 2023 roku, co jasno przedstawia załączona grafika. Takie rozszerzenie zakresu obowiązków eliminuje potrzebę zatrudniania dodatkowych menedżerów – co stanowi korzystną informację dla przedsiębiorców, ale niekorzystną dla osób poszukujących pracy na stanowiskach kierowniczych.
Podsumowanie
Eksperyment przeprowadzony przez Anthropic ukazał imponujące możliwości, jakie już dziś oferują modele sztucznej inteligencji. Nie pozostawia on wątpliwości, że w niedalekiej przyszłości AI znacząco uprości wiele zadań, z którymi obecnie mierzą się osoby na stanowiskach kierowniczych, nie zastępując ich jeszcze ale prowadząc do zmniejszenia liczebości ich występowania.
Tutaj warto zaznaczyć, że model Claudius nadal popełnia liczne błędy. Wbrew zapewnieniom specjalistów z Anthropic, nie wszystkie z nich da się łatwo wyeliminować za pomocą scaffoldingu — wiele problemów ma bowiem charakter strukturalny, co pokazuje choćby kwestia obecności empatii algorytmicznej.
Największą barierą w implementacji AI w roli menedżerów średniego szczebla pozostaje jednak ryzyko halucynacji. Dopiero gdy zostanie ono zredukowane do poziomu w którym wystąpienie tego zjawiska będzie graniczyło z niemal niemożliwym, a nie zaledwie 2–3%, będzie można mówić o realnej szansie na szerokie wdrożenie tych rozwiązań.

